<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>金融投资2023</title>
    <link>/</link>
    <description>Recent content on 金融投资2023</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language><atom:link href="/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title></title>
      <link>/hw/hw1/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/hw/hw1/</guid>
      <description>作业 1 作业一均为问答题, 你可以任选一种提交方式:
纸质版. 手写答案, 在课上将纸质版答案交给任课老师. 请尽量做到字迹工整. 如果你自认为字迹很难辨认, 请选择提交电子版.
电子版. 你可以使用 Word 或 LaTeX 来完成作业, 提交前请先确保文件为 PDF 格式. 教师只接受 PDF 格式的文件.
作业一在线提交地址 问题 为什么我们在使用 Validation dataset 进行模型筛选后, 还要用另外的 Test dataset 来评估模型的预测精度? 为什么直接用 Validation dataset 来评估模型精度, 得到的结果会是有偏的?
注: 实际应用中, 模型在 Validation dataset 上和 Test dataset 上的表现常常相差甚远. 以预测股票涨跌为例, 我们选择的模型可能在 Validation dataset 上的准确率超过 70%, 但在Test dataset 上的准确率只有不到 60%. 阅读关于 Bias-Variance tradeoff 的进一步资料: PDF. 简单谈几个教师在课上没有说到的知识点, 此题中英文回答皆可.
阅读课上幻灯片中, 倒数第二张幻灯片中的三张图, 并解释图中体现的 bias-variance tradeoff.
Hint: The three plots use the same data generation processes as the previous three examples.</description>
    </item>
    
    <item>
      <title></title>
      <link>/hw/hw3/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/hw/hw3/</guid>
      <description>作业 3 问题背景 教科书配套的 R 包 ISLR2 提供了非常丰富的数据集:
当你运行 library(ISLR2) 时, 这些相关的数据集就已经加载到你当下的工作空间中. 以数据集 Wage 为例, 你可以运行 ?Wage 来查看相关文档, 或 head(Wage) 来查看它的前六个观测.
作业说明 从上面的 21 个数据集中, 选择一个数据集, 用它来训练决策树模型和随机森林模型.
用 Quarto或Rmarkdown 来完成本次作业. 你提交的作业, 格式应该类似一个小报告, 它包括以下几个部分:
数据说明. 用中文简短地介绍这个数据集, 以 Wage 为例, 你应该说明:
Wage 数据集的调查对象为美国亚特兰大中部地区3000名男性工人, 它包括11个变量, 如: wage (工人工资), health_ins (是否有健康保险), maritl (婚姻状况), education (教育程度), 等等.
探索性数据分析. 使用任何机器学习模型之前, 你都应该先了解数据集的基本特点, 做一些简单的探索性分析: 计算所有变量的最大值/最小值/均值, 画图看一看变量之间是否存在明显的线性或非线性关系, 计算相关性矩阵, 等等.
这部分内容可以参考课程资料 R语言: 线性回归 Section 2.1. 决策树模型. 首先将数据集按某个比例, 分成训练集和测试集两部分, 调用 tree 包来训练决策树模型, 计算模型在测试集上的均方误.</description>
    </item>
    
    <item>
      <title></title>
      <link>/notes/list/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/notes/list/</guid>
      <description>分组报告 本课程的最终成绩, 由
三次平时作业 最后一次课堂的小组报告 共同组成. 两者各占 50 分.
如果你缺席了最后的小组报告, 也没有提前向教师说明原因. 小组报告视作0分; 根据上面的成绩算法, 你这门课的最终成绩也不会超过50分.
如何分组 两人或三人一组, 自行组队. 组队完成后, 派一位组员告知教师小组的成员信息. (通过QQ或邮箱说明均可)
如果有同学5月25日前, 还没有告诉教师你的组员情况, 会被教师视作&amp;quot;落单成员&amp;quot;. 教师会在 5月26日(周五)的课堂中, 在落单的成员中进行随机匹配.
建议大家积极寻找组员. 因为如果只有你一个人落单, 那么你就只能独自一人完成论文报告. 论文报告要求 每个小组的论文报告时间为 20 到 25 分钟. 可以全程只让一位同学进行报告, 也可以多位小组成员依次报告.
每个小组选讲一篇论文, 论文挑选范围见下面的 Paper List.
Paper List 下面提供的论文仅供参考. 你也可以从其他的地方寻找文章; 只要最后的报告文章, &amp;ldquo;涉及到机器学习和金融&amp;quot;即可. 你可以从每篇文章的文献综述部分出发, 按图索骥, 找一篇你感兴趣的进行报告. 尽管论文挑选的唯一标准是 &amp;ldquo;涉及到机器学习和金融&amp;rdquo;, 教师建议大家 (i) 尽量找新一点的文献 (ii) 尽量选英文文章, 最好是在 Top 期刊已经发表的文章, 因为学生往往很难自行判断文章好坏. Lasso and market returns predictions
Rapach, D. E., J. K.</description>
    </item>
    
    <item>
      <title></title>
      <link>/pre/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/pre/</guid>
      <description>分组报告 本课程的最终成绩, 由
三次平时作业 最后一次课堂的小组报告 共同组成. 两者各占 50 分.
如果你缺席了最后的小组报告, 也没有提前向教师说明原因. 小组报告视作0分; 根据上面的成绩算法, 你这门课的最终成绩也不会超过50分.
如何分组 两人或三人一组, 自行组队. 组队完成后, 派一位组员告知教师小组的成员信息. (通过QQ或邮箱说明均可)
如果有同学5月25日前, 还没有告诉教师你的组员情况, 会被教师视作&amp;quot;落单成员&amp;quot;. 教师会在 5月26日(周五)的课堂中, 在落单的成员中进行随机匹配.
建议大家积极寻找组员. 因为如果只有你一个人落单, 那么你就只能独自一人完成论文报告. 论文报告要求 每个小组的论文报告时间为 20 到 25 分钟. 可以全程只让一位同学进行报告, 也可以多位小组成员依次报告.
每个小组选讲一篇论文, 论文挑选范围见下面的 Paper List.
Paper List 下面提供的论文仅供参考. 你也可以从其他的地方寻找文章; 只要最后的报告文章, &amp;ldquo;涉及到机器学习和金融&amp;quot;即可. 你可以从每篇文章的文献综述部分出发, 按图索骥, 找一篇你感兴趣的进行报告. 尽管论文挑选的唯一标准是 &amp;ldquo;涉及到机器学习和金融&amp;rdquo;, 教师建议大家 (i) 尽量找新一点的文献 (ii) 尽量选英文文章, 最好是在 Top 期刊已经发表的文章, 因为学生往往很难自行判断文章好坏. Lasso and market returns predictions
Rapach, D. E., J. K.</description>
    </item>
    
    <item>
      <title>Quick Q&amp;A</title>
      <link>/notes/quick/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      
      <guid>/notes/quick/</guid>
      <description>Explain why the &amp;ldquo;Nearest Neighbors&amp;rdquo; algorithm fails in a high-dimensional setting.
True or False? Suppose we are interested in learning about a relationship between X and Y. The estimate b₂ in a linear regression that controls for many variables is usually a more reliable measure of a causal relationship than b₁ from a univariate regression on X.
In R, what is the difference between lm(y ~ x*z) and lm(y ~ I(x*z))?</description>
    </item>
    
  </channel>
</rss>
